{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline for GDPR Clause Prediction\n",
    "\n",
    "This notebook details the implementation of a machine learning pipeline designed to predict GDPR clause types and their respective degrees of unfairness using various GPT models.\n",
    "\n",
    "### Overview\n",
    "\n",
    "The code involves several key steps outlined below:\n",
    "\n",
    "- **Utility Functions**:\n",
    "  - `get_system_prompt`: Defines a standard prompt for the model about GDPR analyst's task.\n",
    "  - `get_response`: Fetches model predictions from the OpenAI API.\n",
    "  - `parse_clause_info`: Parses the predicted clause type and degree of unfairness from the model's response.\n",
    "  - `get_clause_type_and_degree_of_unfairness`: Processes a dataframe to predict clause types and degrees of unfairness.\n",
    "\n",
    "- **Model Predictions**:\n",
    "  - **Baseline GPT-3.5 Model Results**: Utilizes the baseline GPT-3.5 model to predict and save clause information.\n",
    "  - **Fine-Tuned GPT-3.5 Model Results**: Employs a fine-tuned GPT-3.5 model specific to GDPR clauses.\n",
    "  - **Zero Shot GPT-4 Model Results**: Uses the latest GPT-4 model in a zero-shot manner to predict GDPR clauses.\n",
    "\n",
    "- **Results Analysis**:\n",
    "  - **Load Predicted Results**: Load the CSV files containing model predictions.\n",
    "  - **Calculate Accuracy Stats**: Compute and display accuracy statistics for training and validation datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from utils import get_training_data, get_validation_data, get_accuracy_stats, read_labelled_data\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT Model Prediction Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_system_prompt():\n",
    "    return \"\"\"\n",
    "        You are a smart GDPR analyst tasked with predicting the 'Type of Clause' and the 'Degree of Unfairness'. \n",
    "\n",
    "        The clause types include 'Unknown', 'Choice of Law', 'Content Removal', 'Unilateral Termination',\n",
    "        'Unilateral Change', 'Contract by Using', 'Limitation of Liability', 'Jurisdiction', and 'Arbitration'.\n",
    "\n",
    "        The 'Degree of Unfairness' is rated from zero to five. For the 'Unknown' type,\n",
    "        the 'Degree of Unfairness' is always zero\n",
    "\n",
    "        Response format: 'Type of Clause: <clause_type>, Degree of Unfairness: <degree_of_unfairness>'\n",
    "    \"\"\"\n",
    "\n",
    "def get_response(client, model_name, clause_text):\n",
    "    try:\n",
    "        response = client.chat.completions.create(model=model_name,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": get_system_prompt()},\n",
    "                {\"role\": \"user\", \"content\": clause_text}\n",
    "            ],\n",
    "        stream=False,\n",
    "        )\n",
    "        response_content = response.choices[0].message.content\n",
    "    except Exception as e:\n",
    "        print(\"Error sending request to OpenAI API, so returning default response\")\n",
    "        response_content = \"Type of Clause: Unknown, Degree of Unfairness: 0\" \n",
    "    return response_content\n",
    "\n",
    "def parse_clause_info(input_str):\n",
    "    parts = input_str.split(',')\n",
    "    result = {}\n",
    "    for part in parts:\n",
    "        key_value = part.split(':')\n",
    "        if len(key_value) == 2:\n",
    "            # Strip any leading or trailing spaces from key and value\n",
    "            key = key_value[0].strip()\n",
    "            value = key_value[1].strip()            \n",
    "            if key == \"Degree of Unfairness\":\n",
    "                try:\n",
    "                    result[key] = int(value)\n",
    "                except ValueError:\n",
    "                    result[key] = None \n",
    "            else:\n",
    "                result[key] = value\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_clause_type_and_degree_of_unfairness(df):\n",
    "    results = []\n",
    "    for clause_text in tqdm(df['content'].values):\n",
    "        response = get_response(client, model_name, clause_text)\n",
    "        parsed_response = parse_clause_info(response)\n",
    "        results.append(parsed_response)\n",
    "    \n",
    "    df['predicted_clause_type'] = [result.get('Type of Clause', None) for result in results]\n",
    "    df['predicted_degree_of_unfairness'] = [result.get('Degree of Unfairness', None) for result in results]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Baseline GPT3.5 Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# client = OpenAI()\n",
    "# model_name = \"gpt-3.5-turbo\"\n",
    "# system_prompt = get_system_prompt()\n",
    "\n",
    "# training_df = get_training_data()\n",
    "# validation_df = get_validation_data()\n",
    "# labeled_training_df = get_clause_type_and_degree_of_unfairness(training_df.copy())\n",
    "# labeled_validation_df = get_clause_type_and_degree_of_unfairness(validation_df.copy())\n",
    "# labeled_training_df.to_csv(f'labeled_training_data_{model_name}.csv', index=False)\n",
    "# labeled_validation_df.to_csv(f'labeled_validation_data_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get FineTuned_GPT3.5 Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI()\n",
    "# model_name = \"ft:gpt-3.5-turbo-1106:personal:gdpr-trial-2:9Gl2wNWI\"\n",
    "# system_prompt = get_system_prompt()\n",
    "\n",
    "# validation_df = get_validation_data()\n",
    "# labeled_validation_df = get_clause_type_and_degree_of_unfairness(validation_df)\n",
    "# labeled_validation_df.to_csv(f'labeled_validation_data_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Zero Shot GPT-4-turbo Model Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client = OpenAI()\n",
    "# model_name = \"gpt-4-turbo-2024-04-09\"\n",
    "# system_prompt = get_system_prompt()\n",
    "\n",
    "# validation_df = get_validation_data()\n",
    "# labeled_validation_df = get_clause_type_and_degree_of_unfairness(validation_df)\n",
    "# labeled_validation_df.to_csv(f'labeled_validation_data_{model_name}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Predicted GPT-3.turbo Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data accuracy: {'Type of Clause': 0.13164049448713666, 'Degree of Unfairness': 0.17607751419979953, 'Combined': 0.11359839625793518}\n",
      "Validation data accuracy: {'Type of Clause': 0.14454045561665357, 'Degree of Unfairness': 0.19795758051846032, 'Combined': 0.12647289866457187}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-3.5-turbo\"\n",
    "labeled_training_df = read_labelled_data(f'labeled_training_data_{model_name}.csv')\n",
    "labeled_validation_df = read_labelled_data(f'labeled_validation_data_{model_name}.csv')\n",
    "\n",
    "training_stats=get_accuracy_stats(labeled_training_df)\n",
    "validation_stats=get_accuracy_stats(labeled_validation_df)\n",
    "\n",
    "print(f\"Training data accuracy: {training_stats}\")\n",
    "print(f\"Validation data accuracy: {validation_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load FineTuned GPT-3.turbo Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data accuracy: {'Type of Clause': 0.11468970934799685, 'Degree of Unfairness': 0.9167321288295365, 'Combined': 0.11468970934799685}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"ft:gpt-3.5-turbo-1106:personal:gdpr-trial-2:9Gl2wNWI\"\n",
    "\n",
    "labeled_validation_df = read_labelled_data(f'labeled_validation_data_{model_name}.csv')\n",
    "validation_stats=get_accuracy_stats(labeled_validation_df)\n",
    "print(f\"Validation data accuracy: {validation_stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Predicted GPT-4-turbo Baseline Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data accuracy: {'Type of Clause': 0.1720345640219953, 'Degree of Unfairness': 0.19088766692851533, 'Combined': 0.1633935585231736}\n"
     ]
    }
   ],
   "source": [
    "model_name = \"gpt-4-turbo-2024-04-09\"\n",
    "\n",
    "labeled_validation_df = read_labelled_data(f'labeled_validation_data_{model_name}.csv')\n",
    "validation_stats=get_accuracy_stats(labeled_validation_df)\n",
    "print(f\"Validation data accuracy: {validation_stats}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
